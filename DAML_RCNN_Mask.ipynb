{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Assist Machine Learning Using RCNN-Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Mask R-CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-CNN stands for \"Regions with CNN features\", CNN stands for \"Convolutional Neural Network\".\n",
    "\n",
    "- R-CNN grabs parts of an image (or region) as a bounding box, and computes each region for CNN features,\n",
    "it then classifies each region to determine what it is through ROI align, testing pixel by pixel to form the mask. \n",
    "R-CNN then takes the output from the ROI align and helps generate the bounding boxes and classifies the target to determine what it is.\n",
    "\n",
    "- Mask R-CNN goes through a process of pixel-level classification with convolutional neural networks to mask over cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from soco import coco\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the code is specifying the path to the appropiate directories, while also grabbing the weights for the pre-trained model. \n",
    "\n",
    "The mask_rcnn_coco.h5 file is a pre-trained dataset provided by matterport that act as weights for MS COCO. \n",
    "\n",
    "It is mask-RCNN trained for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirMain = os.path.abspath(\"./\")\n",
    "dirModel = os.path.join(dirMain, \"logs\")\n",
    "sys.path.append(os.path.join(dirMain,\"/coco/\"))\n",
    "path_Coco = os.path.join(dirMain, \"mrcnn/mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuration object is required to make an inference for the Mask_RCNN instance.\n",
    "\n",
    "The configuration is set to specify the number of images per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configure_coco(coco.CocoConfig):\n",
    "    # Since we are running inference 1 image at a time, batch size is set to 1. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an object of class Configure_coco to configure the masking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nConfig = Configure_coco()\n",
    "nConfig.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaskRCNN instance object created in inference mode since this mode is used to make estimations for a given image, the dirModel variable is the path to where the log messages will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrcnn_model = modellib.MaskRCNN(\n",
    "    mode=\"inference\", model_dir=dirModel, config=nConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights that will be used to calculate the estimations, and assist in classifying the detected object in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrcnn_model.load_weights(path_Coco, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification types to compare to for the given trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "    'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function applies a cyan coloured mask with a 50% opacity to the ROI detected in the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(cyan_col, mask, source, transp=0.5):\n",
    "    for n, c in enumerate(cyan_col):\n",
    "        source[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            source[:, :, n] * (1 - transp) + transp * c,\n",
    "            source[:, :, n]\n",
    "        )\n",
    "    return source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mask, bounding box, and classification to the region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_frame(source, region_interest, masks, class_ids, cls_names, scores):\n",
    "    # Number of instances found in ROI\n",
    "    n_instances = region_interest.shape[0]\n",
    "    if not n_instances:\n",
    "        print('NO Instances FOUND in ROI')\n",
    "    else:\n",
    "        assert region_interest.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "    # For each instance found apply mask, box, and label\n",
    "    for i in range(n_instances):\n",
    "        # Detect only road obstacles from the class names specified in the class_names array above. class_names[1 .. 14]\n",
    "        if class_ids[i] in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]:\n",
    "            if not np.any(region_interest[i]):\n",
    "                continue\n",
    "            \n",
    "            # Coordinates for region of interest\n",
    "            y1, x1, y2, x2 = region_interest[i]\n",
    "            # Classification for the ROI\n",
    "            label = class_names[class_ids[i]]\n",
    "            # Confidence score in relation to its classification\n",
    "            score = scores[i] if scores is not None else None\n",
    "            # Store classification and score as a string caption to the object detected to be used as a label\n",
    "            caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "            mask = masks[:, :, i]\n",
    "            \n",
    "            # Cyan color for mask / bounding box / label in BGR  \n",
    "            cyan_col = (240,252,3)\n",
    "            # Apply the mask on the detected object\n",
    "            source = apply_mask(cyan_col, mask, source)\n",
    "            # Draw bounding box using the x/y coordinates from the roi on the detected object\n",
    "            source = cv2.rectangle(source, (x1, y1), (x2, y2), cyan_col, 1)\n",
    "            # Write the label classification above the detected object using the x/y coordinates\n",
    "            source = cv2.putText(\n",
    "                source, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, cyan_col, 1\n",
    "            )\n",
    "    return source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Captured Video Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = cv2.VideoCapture(\"VideoSourceFile/Freewaytest.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get original video size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width  = stream.get(cv2.CAP_PROP_FRAME_WIDTH)  # float value, converted to integer in the next line when writing\n",
    "height = stream.get(cv2.CAP_PROP_FRAME_HEIGHT) # float value, converted to integer in the next line when writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create VideoWriter object.\n",
    "\n",
    "0x7634706d  is the (*'MP4V') video writing formatting, with an output resolution of the original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = cv2.VideoWriter('OutputVideo/output.mp4', 0x7634706d, 60.0, (int(width),int(height)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start capturing footage frame by frame and apply mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start capturing footage frame by frame and apply mask\n",
    "while True:\n",
    "    # read in the stream wether its live camera feed or a video footage\n",
    "    is_streaming , frame = stream.read()\n",
    "    if not is_streaming:\n",
    "        print(\"Finished stream, ending program\")\n",
    "        break\n",
    "    #Make a prediction with the model creating a dictionary with a set of key value pairs that list possible objects detected \n",
    "    get_frame_results = mrcnn_model.detect([frame], verbose=1)\n",
    "\n",
    "    # Apply the bounding boxes, mask and classification to the footage after setting up the dictionary of key value pairs \n",
    "    # Following keypoints in the dictionary\n",
    "    # rois: Bounding boxes / regions of interest (ROI) for objects detected\n",
    "    # masks: Masks to generate for objects detected \n",
    "    # class_ids: Reference to the classification types\n",
    "    # scores: Confidence score in relation to its classification to determine what it is\n",
    "    detected_frame = get_frame_results[0]\n",
    "    masked_image = mask_frame(frame, detected_frame['rois'], detected_frame['masks'], detected_frame['class_ids'], \n",
    "                            class_names, detected_frame['scores'])\n",
    "    # Write to the video output\n",
    "    video_output.write(masked_image)\n",
    "    cv2.imshow(\"Driver Assist Machine Learning RCNN Mask\",masked_image)\n",
    "    # Press 'q' to exit the program early, the output video file will still be generated if terminated early\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release Stream and video writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.release()\n",
    "video_output.release()\n",
    "cv2.destroyWindow(\"Driver Assist Machine Learning RCNN Mask\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
